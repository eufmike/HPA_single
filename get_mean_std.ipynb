{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.0+cu118\n",
      "Torchvision version: 0.15.1+cu118\n",
      "CUDA is available: True\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "# print(os.getcwd())\n",
    "# sys.path.append(os.getcwd())\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Torchvision version:\", torchvision.__version__)\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir= Path('/dlab/ldrive/CBT/USLJ-DSDE_DATA-I10008/BenchmarkDatasets/hpa-single-cell-image-classification')\n",
    "train_dataset_dir = datadir.joinpath('train')\n",
    "train_csv = datadir.joinpath('train_select_1K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/runtime_env/miniconda3/envs/mspytorch/lib/python3.9/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/runtime_env/miniconda3/envs/mspytorch/lib/python3.9/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "from func.HPASCDataset import HPASCDataset, TrDataset\n",
    "from func.trainer import load_train_objs\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor, Resize, v2\n",
    "input_ch_ct = 4\n",
    "debug_size = 100\n",
    "n_class = 19\n",
    "\n",
    "tf_dataset = Compose(\n",
    "    [\n",
    "        ToTensor(), \n",
    "        Resize(size = (1024, 1024), antialias = True),\n",
    "    ]\n",
    "\n",
    ")\n",
    "HPA_dataset = HPASCDataset(\n",
    "                        input_csv = train_csv, \n",
    "                        root = train_dataset_dir, \n",
    "                        input_ch_ct = input_ch_ct,\n",
    "                        n_class = n_class, \n",
    "                        debug_size = debug_size,\n",
    "                        transform = tf_dataset\n",
    "                        )\n",
    "\n",
    "dataloader = DataLoader(\n",
    "                    HPA_dataset,\n",
    "                    batch_size=64,\n",
    "                    pin_memory=True,\n",
    "                    num_workers=32,\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std(loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images_count = 0\n",
    "    for data in tqdm(loader):\n",
    "        images = data['image']\n",
    "        image_count_in_a_batch = images.size(0)\n",
    "        # print(images.shape)\n",
    "        images = images.view(image_count_in_a_batch, images.size(1), -1)\n",
    "        # print(images.shape)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total_images_count += image_count_in_a_batch\n",
    "    \n",
    "    mean /= total_images_count\n",
    "    std /= total_images_count\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:24<00:00, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0516, 0.0472, 0.0755, 0.0821])\n",
      "tensor([0.1351, 0.0812, 0.1244, 0.1252])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mean_100, std_100 = get_mean_and_std(dataloader)\n",
    "print(mean_100)\n",
    "print(std_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transform_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/get_mean_std.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blinuxbox/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/get_mean_std.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m HPA_dataset \u001b[39m=\u001b[39m HPASCDataset(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blinuxbox/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/get_mean_std.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m                         input_csv \u001b[39m=\u001b[39m train_csv, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blinuxbox/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/get_mean_std.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                         root \u001b[39m=\u001b[39m train_dataset_dir, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blinuxbox/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/get_mean_std.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m                         input_ch_ct \u001b[39m=\u001b[39m input_ch_ct,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blinuxbox/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/get_mean_std.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m                         n_class \u001b[39m=\u001b[39m n_class, \n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blinuxbox/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/get_mean_std.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m                         transform \u001b[39m=\u001b[39m transform_dataset\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blinuxbox/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/get_mean_std.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m                         )\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blinuxbox/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/get_mean_std.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blinuxbox/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/get_mean_std.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m                     HPA_dataset,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blinuxbox/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/get_mean_std.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m                     batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blinuxbox/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/get_mean_std.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m                     pin_memory\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blinuxbox/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/get_mean_std.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m                     num_workers\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blinuxbox/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/get_mean_std.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m                     shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blinuxbox/dlab/ldrive/CBT/USLJ-DSDE-I10007/DSDE/shihch3/code/p/python/HPA_single/get_mean_std.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m mean_1k, std_1k \u001b[39m=\u001b[39m get_mean_and_std(dataloader)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transform_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "HPA_dataset = HPASCDataset(\n",
    "                        input_csv = train_csv, \n",
    "                        root = train_dataset_dir, \n",
    "                        input_ch_ct = input_ch_ct,\n",
    "                        n_class = n_class, \n",
    "                        transform = tf_dataset\n",
    "                        )\n",
    "\n",
    "dataloader = DataLoader(\n",
    "                    HPA_dataset,\n",
    "                    batch_size=64,\n",
    "                    pin_memory=True,\n",
    "                    num_workers=32,\n",
    "                    shuffle=False)\n",
    "\n",
    "mean_1k, std_1k = get_mean_and_std(dataloader)\n",
    "print(mean_1k)\n",
    "print(std_1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [04:01<00:00, 10.08s/it]\n"
     ]
    }
   ],
   "source": [
    "train_csv = datadir.joinpath('train.csv')\n",
    "\n",
    "HPA_dataset = HPASCDataset(\n",
    "                        input_csv = train_csv, \n",
    "                        root = train_dataset_dir, \n",
    "                        input_ch_ct = input_ch_ct,\n",
    "                        n_class = n_class,\n",
    "                        debug_size = 3000, \n",
    "                        transform = tf_dataset\n",
    "                        )\n",
    "\n",
    "dataloader = DataLoader(\n",
    "                    HPA_dataset,\n",
    "                    batch_size=128,\n",
    "                    pin_memory=True,\n",
    "                    num_workers=32,\n",
    "                    shuffle=False)\n",
    "\n",
    "mean_full, std_full = get_mean_and_std(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0496, 0.0483, 0.0711, 0.0789])\n",
      "tensor([0.1344, 0.0795, 0.1200, 0.1196])\n",
      "tensor([0.0480, 0.0442, 0.0724, 0.0723])\n",
      "tensor([0.1302, 0.0767, 0.1202, 0.1153])\n",
      "tensor([0.0540, 0.0530, 0.0804, 0.0806])\n",
      "tensor([0.1420, 0.0831, 0.1272, 0.1229])\n"
     ]
    }
   ],
   "source": [
    "print(mean_100)\n",
    "print(std_100)\n",
    "print(mean_1k)\n",
    "print(std_1k)\n",
    "print(mean_full)\n",
    "print(std_full)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
